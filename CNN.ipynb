{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas\n",
    "import csv\n",
    "from PIL import Image\n",
    "import sys\n",
    "import random as rnd\n",
    "import copy\n",
    "\n",
    "%run ./img_util.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_table = {'neutral'  : 0, \n",
    "                 'happiness': 1, \n",
    "                 'surprise' : 2, \n",
    "                 'sadness'  : 3, \n",
    "                 'anger'    : 4, \n",
    "                 'disgust'  : 5, \n",
    "                 'fear'     : 6, \n",
    "                 'contempt' : 7}\n",
    "base_path = os.path.join(\".\", \"fer2013\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folders = os.path.join(base_path,'FER2013Train')\n",
    "valid_folders = os.path.join(base_path,'FER2013Valid') \n",
    "test_folders  = os.path.join(base_path,'FER2013Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(emotion_raw, mode=\"mayority\"):\n",
    "    '''\n",
    "    Based on https://arxiv.org/abs/1608.01041, we process the data differently depend on the training mode:\n",
    "    Majority: return the emotion that has the majority vote, or unknown if the count is too little.\n",
    "    Crossentropty: convert the count into probability distribution.abs\n",
    "    '''        \n",
    "    size = len(emotion_raw)\n",
    "    emotion_unknown     = [0.0] * size\n",
    "    emotion_unknown[-2] = 1.0\n",
    "\n",
    "    # remove emotions with a single vote (outlier removal) \n",
    "    for i in range(size):\n",
    "        if emotion_raw[i] < 1.0 + sys.float_info.epsilon:\n",
    "            emotion_raw[i] = 0.0\n",
    "\n",
    "    sum_list = sum(emotion_raw)\n",
    "    emotion = [0.0] * size \n",
    "\n",
    "    if mode == 'majority': \n",
    "        # find the peak value of the emo_raw list \n",
    "        maxval = max(emotion_raw) \n",
    "        if maxval > 0.5*sum_list: \n",
    "            emotion[np.argmax(emotion_raw)] = maxval \n",
    "        else: \n",
    "            emotion = emotion_unknown   # force setting as unknown \n",
    "    elif (mode == 'crossentropy'):\n",
    "        sum_part = 0\n",
    "        count = 0\n",
    "        valid_emotion = True\n",
    "        while sum_part < 0.75*sum_list and count < 3 and valid_emotion:\n",
    "            maxval = max(emotion_raw) \n",
    "            for i in range(size): \n",
    "                if emotion_raw[i] == maxval: \n",
    "                    emotion[i] = maxval\n",
    "                    emotion_raw[i] = 0\n",
    "                    sum_part += emotion[i]\n",
    "                    count += 1\n",
    "                    if i >= 8:  # unknown or non-face share same number of max votes \n",
    "                        valid_emotion = False\n",
    "                        if sum(emotion) > maxval:   # there have been other emotions ahead of unknown or non-face\n",
    "                            emotion[i] = 0\n",
    "                            count -= 1\n",
    "                        break\n",
    "        if sum(emotion) <= 0.5*sum_list or count > 3: # less than 50% of the votes are integrated, or there are too many emotions, we'd better discard this example\n",
    "            emotion = emotion_unknown   # force setting as unknown \n",
    "            \n",
    "    return [float(i)/sum(emotion) for i in emotion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder, mode):\n",
    "    names = []\n",
    "    data = []\n",
    "    labels = []\n",
    "    per_emotion_count = np.zeros(len(emotion_table), dtype=np.int)\n",
    "    in_label_path = os.path.join(folder, \"label.csv\")\n",
    "    with open(in_label_path) as csvfile: \n",
    "        emotion_label = csv.reader(csvfile) \n",
    "        for row in emotion_label:\n",
    "            # load the image\n",
    "            image_path = os.path.join(folder, row[0])\n",
    "            img_data = Image.open(image_path)\n",
    "            rgb_im = img_data.convert(\"RGB\")\n",
    "            \n",
    "            rotated_image = rgb_im.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            \n",
    "            rgb_im.load()\n",
    "            rotated_image.load()\n",
    "                        \n",
    "            emotion_raw = list(map(float, row[2:len(row)]))\n",
    "            emotion = process_data(emotion_raw, mode)\n",
    "            \n",
    "            idx = np.argmax(emotion)\n",
    "            if idx < len(emotion_table): # not unknown or non-face \n",
    "                emotion = emotion[:-2]\n",
    "                emotion = [float(i)/sum(emotion) for i in emotion]\n",
    "                names.append(image_path)\n",
    "                names.append(\"rotated_\"+image_path)\n",
    "                data.append(np.array(rotated_image).tolist())\n",
    "                data.append(np.array(rgb_im).tolist())\n",
    "                labels.append(emotion)\n",
    "                labels.append(emotion)\n",
    "                per_emotion_count[idx] += 1\n",
    "    return names, data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, x_train, y_train = load_data(train_folders, \"crossentropy\") #Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, x_valid, y_valid = load_data(valid_folders, \"majority\") #Valid Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, x_test, y_test = load_data(test_folders, \"majority\") #Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (48, 48, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "classifier.add(Conv2D(32, (2, 2), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "classifier.add(Conv2D(64, (2, 2), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (3,3)))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "classifier.add(Dense(1024, activation = \"relu\"))\n",
    "classifier.add(Dense(len(emotion_table), activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_, x_train, y_train = np.transpose(np.array(train_data))\n",
    "#_, x_valid, y_valid = np.transpose(np.array(valid_data))\n",
    "#_, x_test, y_test = np.transpose(np.array(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow(np.array(x_train),\n",
    "                                 y=y_train,\n",
    "                                 batch_size=32,\n",
    "                                 seed=256)\n",
    "\n",
    "valid_set = train_datagen.flow(np.array(x_valid),\n",
    "                                 y=y_valid,\n",
    "                                 batch_size=32,\n",
    "                                 seed=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/frhec/PycharmProjects/CCN/venv/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/25\n",
      "55894/55894 [==============================] - 4458s 80ms/step - loss: 0.6898 - acc: 0.7866 - val_loss: 0.6759 - val_acc: 0.7710\n",
      "Epoch 2/25\n",
      "55894/55894 [==============================] - 3316s 59ms/step - loss: 0.4851 - acc: 0.8588 - val_loss: 0.7400 - val_acc: 0.7621\n",
      "Epoch 3/25\n",
      "55894/55894 [==============================] - 3262s 58ms/step - loss: 0.4408 - acc: 0.8706 - val_loss: 0.7143 - val_acc: 0.7696\n",
      "Epoch 4/25\n",
      "55894/55894 [==============================] - 3245s 58ms/step - loss: 0.4192 - acc: 0.8760 - val_loss: 0.7415 - val_acc: 0.7638\n",
      "Epoch 5/25\n",
      "55894/55894 [==============================] - 3240s 58ms/step - loss: 0.4056 - acc: 0.8791 - val_loss: 0.7273 - val_acc: 0.7700\n",
      "Epoch 6/25\n",
      "55894/55894 [==============================] - 3320s 59ms/step - loss: 0.3966 - acc: 0.8810 - val_loss: 0.7467 - val_acc: 0.7711\n",
      "Epoch 7/25\n",
      " 3617/55894 [>.............................] - ETA: 1:09:51 - loss: 0.3933 - acc: 0.8812"
     ]
    }
   ],
   "source": [
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = len(x_train),\n",
    "                         epochs = 25,\n",
    "                         validation_data = valid_set,\n",
    "                         validation_steps = len(x_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
